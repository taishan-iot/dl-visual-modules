// src/components/DL/TrueBackpropSimulator.jsx
import React, { useState, useMemo } from 'react';
import { Bar } from 'react-chartjs-2';
import DeepLearningGlossary from './DeepLearningGlossary';

// æ¿€æ´»å‡½æ•¸å®šç¾©
const activationFunctions = {
 relu: {
  label: 'ReLU',
  fn: (x) => Math.max(0, x),
  derivative: (x) => (x > 0 ? 1 : 0),
 },
 sigmoid: {
  label: 'Sigmoid',
  fn: (x) => 1 / (1 + Math.exp(-x)),
  derivative: (x) => {
   const s = 1 / (1 + Math.exp(-x));
   return s * (1 - s);
  },
 },
};

// åˆå§‹åŒ–ç­–ç•¥
const initStrategies = {
 random: () => Math.random() * 2 - 1,
 xavier: () => Math.random() * Math.sqrt(1 / 4),
 he: () => Math.random() * Math.sqrt(2 / 4),
};

const TrueBackpropSimulator = () => {
 const [activation, setActivation] = useState('relu');
 const [init, setInit] = useState('xavier');

 // ç¶²è·¯è¶…åƒæ•¸
 const layers = 5;
 const neurons = 4;
 const input = useMemo(() => Array(neurons).fill(0).map(() => Math.random()), []);
 const target = useMemo(() => Array(neurons).fill(0.5), []);

 // ä½¿ç”¨ useMemo é€²è¡Œæ€§èƒ½å„ªåŒ–
 const { weights, forward, z_values, output, loss, gradients } = useMemo(() => {
  // åˆå§‹åŒ–æ¬Šé‡
  const weights = Array(layers).fill(0).map(() =>
   Array(neurons).fill(0).map(() => initStrategies[init]())
  );

  // å‰å‘å‚³æ’­
  const forward = [];
  const z_values = []; // ä¿å­˜æ¿€æ´»å‡½æ•¸çš„è¼¸å…¥å€¼
  forward[0] = input;
  z_values[0] = input;

  for (let l = 1; l < layers; l++) {
   forward[l] = [];
   z_values[l] = [];
   for (let i = 0; i < neurons; i++) {
    const z = forward[l - 1].reduce((sum, x, j) => sum + x * weights[l][j], 0);
    z_values[l][i] = z;
    forward[l][i] = activationFunctions[activation].fn(z);
   }
  }

  const output = forward[layers - 1];

  // æå¤±è¨ˆç®—
  const loss = output.reduce((sum, y, i) => sum + Math.pow(y - target[i], 2), 0) / neurons;

  // åå‘å‚³æ’­
  const gradients = [];
  // è¼¸å‡ºå±¤çš„æ¢¯åº¦
  gradients[layers - 1] = output.map((y, i) => 2 * (y - target[i]));

  // å¾å€’æ•¸ç¬¬äºŒå±¤é–‹å§‹åå‘è¨ˆç®—
  for (let l = layers - 2; l >= 0; l--) {
   gradients[l] = [];
   for (let i = 0; i < neurons; i++) {
    // ä¾†è‡ªå¾Œä¸€å±¤æ‰€æœ‰ç¥ç¶“å…ƒçš„æ¢¯åº¦ä¹‹å’Œ
    const gradientSumFromNextLayer = gradients[l + 1].reduce(
     (sum, grad_next, j) => sum + grad_next * weights[l + 1][j],
     0
    );
    // ä¹˜ä»¥æœ¬å±¤ç¥ç¶“å…ƒæ¿€æ´»å‡½æ•¸çš„å°æ•¸
    gradients[l][i] = gradientSumFromNextLayer * activationFunctions[activation].derivative(z_values[l][i]);
   }
  }

  return { weights, forward, z_values, output, loss, gradients };
 }, [activation, init, layers, neurons, input, target]);

 // åœ–è¡¨æ•¸æ“š
 const chartData = useMemo(() => ({
  labels: Array.from({ length: layers }, (_, i) => `L${i + 1}`),
  datasets: [
   {
    label: 'æ¯å±¤å¹³å‡æ¢¯åº¦å€¼',
    data: gradients.map((g) =>
     parseFloat((g.reduce((a, b) => a + Math.abs(b), 0) / g.length).toFixed(4))
    ),
    backgroundColor: '#10b981',
   },
  ],
 }), [gradients, layers]);

 const chartOptions = {
  scales: {
   y: { beginAtZero: true, max: 1 },
  },
  plugins: {
   legend: { display: false },
  },
 };

 return (
  <div className="p-4 bg-white rounded shadow" id="module-true-backprop">
   <h2 className="text-xl font-bold mb-4">ğŸ§© çœŸå¯¦åå‘å‚³æ’­æ¨¡æ“¬å™¨</h2>

   {/* æ¿€æ´»å‡½æ•¸èˆ‡åˆå§‹åŒ–ç­–ç•¥é¸æ“‡å™¨ */}
   <div className="mb-4 flex space-x-6">
    <div>
     <label className="font-medium mr-2">æ¿€æ´»å‡½æ•¸ï¼š</label>
     <select
      value={activation}
      onChange={(e) => setActivation(e.target.value)}
      className="border px-2 py-1 rounded"
     >
      <option value="relu">ReLU</option>
      <option value="sigmoid">Sigmoid</option>
     </select>
    </div>
    <div>
     <label className="font-medium mr-2">åˆå§‹åŒ–ç­–ç•¥ï¼š</label>
     <select
      value={init}
      onChange={(e) => setInit(e.target.value)}
      className="border px-2 py-1 rounded"
     >
      <option value="random">Random</option>
      <option value="xavier">Xavier</option>
      <option value="he">He</option>
     </select>
    </div>
   </div>

   {/* æå¤±é¡¯ç¤º */}
   <div className="mb-4 text-sm text-gray-700">
    <p>æ¨¡æ“¬è¼¸å‡ºå€¼ï¼š<strong>{output.map((v) => v.toFixed(2)).join(', ')}</strong></p>
    <p>ç›®æ¨™å€¼ï¼š<strong>{target.join(', ')}</strong></p>
    <p>å‡æ–¹èª¤å·®ï¼ˆMSEï¼‰ï¼š<strong>{loss.toFixed(4)}</strong></p>
   </div>

   {/* æ¢¯åº¦è¦–è¦ºåŒ– */}
   <div className="mb-6">
    <h3 className="text-lg font-semibold mb-2">ğŸ“Š æ¯å±¤å¹³å‡æ¢¯åº¦å€¼</h3>
    <Bar data={chartData} options={chartOptions} />
    <p className="mt-2 text-sm text-gray-500">
     æ¢¯åº¦å€¼è¶Šç©©å®šï¼Œæ¨¡å‹è¶Šå®¹æ˜“è¨“ç·´ï¼›è‹¥æ¢¯åº¦æ¶ˆå¤±æˆ–çˆ†ç‚¸ï¼Œæ¨¡å‹å°‡é›£ä»¥æ”¶æ–‚ã€‚
    </p>
   </div>

   {/* è©å½™è§£é‡‹å€ */}
   <div className="mb-6">
    <h3 className="text-lg font-semibold mb-2">ğŸ” è©å½™è§£é‡‹</h3>
    <DeepLearningGlossary
      selected={['TrueBackpropSimulator', 'Backpropagation', 'Gradient Vanishing', 'Gradient Exploding']}
    />
   </div>

   {/* æ•™å­¸è£œå…… */}
   <div className="text-sm text-gray-600">
    <p>
     å±•ç¤ºäº†åå‘å‚³æ’­ä¸­æ¢¯åº¦å¦‚ä½•åœ¨ä¸åŒå±¤æµå‹•ï¼Œä¸¦å—æ¿€æ´»å‡½æ•¸èˆ‡åˆå§‹åŒ–ç­–ç•¥å½±éŸ¿ã€‚
    </p>
    <p className="mt-2">
     å¯ä»¥é€²ä¸€æ­¥æ¢ç´¢ BatchNormã€Dropoutã€ä¸åŒæå¤±å‡½æ•¸å°æ¢¯åº¦ç©©å®šæ€§çš„å½±éŸ¿ã€‚
    </p>
   </div>
  </div>
 );
};

// è«‹å°‡å®ƒæ›¿æ›æˆé è¨­åŒ¯å‡º
export default TrueBackpropSimulator;